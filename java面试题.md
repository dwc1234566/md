

# ***1.为什么string设计为不可变***   （不考虑反射特殊场景）

   ![](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124172328117.png)

**string被final修饰，不可继承**

**string的value是不可变的**

![image-20230124172708557](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124172708557.png)

**一 ，多个相同的字符串共同指向一个值，节省空间。**

二，用作HashMap的key，HashCode不变。

三，缓存HashCode，创建了string对象hash不变。用的时候，不用重新计算。

![image-20230124173354785](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124173354785.png)

三，线程安全，不可变被多个线程共享进行同步操作。





# *2.如何设计一个类似于Dubbo的RPC框架*

**什么是rpc框架**

![image-20230124190532097](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124190532097.png)

![image-20230212133822553](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230212133822553.png)

`1.服务集成 RPC 后，服务（这里的服务就是图中的 Provider，服务提供者）启动后会通过 Register（注册）模块，把服务的唯一 ID 和 IP 地址，端口信息等注册到 RPC 框架注册中心（图中的 Registry 部分）。`
`2.当调用者（Consumer）想要调用服务的时候，通过 Provider 注册时的的服务唯一 ID 去注册中心查找在线可供调用的服务，返回一个 IP 列表（3.notify 部分）。`
`3.第三步 Consumer 根据一定的策略，比如随机 or 轮训从 Registry 返回的可用 IP 列表真正调用服务（4.invoke）。`
`4。最后是统计功能，RPC 框架都提供监控功能，监控服务健康状况，控制服务线上扩展和上下线（5.count）`



# *3.为什么阿里巴巴不建议使用Executors创建线程池*



![image-20230124191224318](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124191224318.png)

```
newFixedThreadPool用的没有上限的queue，如果任务的处理速度比较慢，当队列占用内存过多有可能发生oom
```

![image-20230124191548144](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124191548144.png)

# *4.根据实际需要，定制自己的线程池 new ThreadPoolExecutor*

 ![image-20230124192317624](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124192317624.png)

​      线程工厂，和拒绝执行策略。当线程池慢后，执行决绝策略。

![image-20230124192926637](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124192926637.png)





# *5.  CAS有什么缺点*

![image-20230124193542234](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230124193542234.png)

`1.ABA问题。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了，ABA问题解决的思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A.从jdk1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。`

`2.循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。`

`3.只能保证一个共享变量的原子操作。不能操作一个代码块。`





# 6.*你知道线程池线程复用的原理吗*

![image-20230125172511381](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230125172511381.png)

`**当任务提交之后，线程池首先会检查当前线程数，如果当前的线程数小于核心线程数（corePoolSize），则新建线程并执行任务。`

`当提交的任务不断增加，创建的线程数等于核心线程数（corePoolSize），新增的任务会被添加到 workQueue 任务队列中，等待核心线程执行完当前任务后，重新从 workQueue 中获取任务执行。`

`当任务数量达到了 workQueue 的最大容量，但是当前线程数小于最大线程数（maximumPoolSize），线程池会在核心线程数（corePoolSize）的基础上继续创非核心建线程来执行任务。`

`当任务继续增加，线程池的线程数达到最大线程数（maximumPoolSize），这个时候线程池就会采用拒绝策略来拒绝这些任务。`



# 7.*阻塞和非阻塞队列的并发安全原理是什么*

![image-20230125190910212](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230125190910212.png) 

阻塞队列ArrayBlockingQueue利用了可重入锁。

```java
/**
 * Inserts the specified element at the tail of this queue, waiting
 * for space to become available if the queue is full.
 *
 * @throws InterruptedException {@inheritDoc}
 * @throws NullPointerException {@inheritDoc}
 */
public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}
```

并发队列ConcurrentLinkedQueue，使用了cas，乐观锁原理



# *8.你对“非公平锁”了解吗，为什么会有非公平锁*

![image-20230129190214040](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230129190214040.png)



# *9 你对自旋锁了解吗？ 优点和缺点分别是什么？*



![image-20230129191147157](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230129191147157.png)

`优点：轻量级锁，省去了线程状态切换的开销，休眠到运行`

`缺点：自旋增加了新的内存开销`

`如果线程执行周期很长，如io密集型操作，就可以用非自旋锁`





# 10 合适的线程数量是多少？  CPU核心数和线程数的关系？**

![image-20230129192040742](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230129192040742.png)

### `CPU密集型`

`CPU密集型也叫计算密集型，指的是系统的硬盘、内存性能相对CPU要好很多，此时，系统运作CPU读写IO(硬盘/内存)时，IO可以在很短的时间内完成，而CPU还有许多运算要处理，因此，CPU负载很高。`

`CPU密集表示该任务需要大量的运算，而没有阻塞，CPU一直全速运行。CPU密集任务只有在真正的多核CPU上才可能得到加速（通过多线程），而在单核CPU上，无论你开几个模拟的多线程该任务都不可能得到加速，因为CPU总的运算能力就只有这么多。`

`CPU使用率较高（例如:计算圆周率、对视频进行高清解码、矩阵运算等情况）的情况下，通常，线程数只需要设置为CPU核心数的线程个数就可以了。 这一情况多出现在一些业务复杂的计算和逻辑处理过程中。比如说，现在的一些机器学习和深度学习的模型训练和推理任务，包含了大量的矩阵运算。`

`CPU密集型核心线程数 = CPU核数 + 1`

通过该方法获取可用核心数

```java
Runtime.getRuntime().availableProcessors()
```



### `IO密集型`

`IO密集型指的是系统的CPU性能相对硬盘、内存要好很多，此时，系统运作，大部分的状况是CPU在等IO (硬盘/内存) 的读写操作，因此，CPU负载并不高。`

`密集型的程序一般在达到性能极限时，CPU占用率仍然较低。这可能是因为任务本身需要大量I/O操作，而程序的逻辑做得不是很好，没有充分利用处理器能力。`

`CPU 使用率较低，程序中会存在大量的 I/O 操作占用时间，导致线程空余时间很多，通常就需要开CPU核心数数倍的线程。`

`其计算公式为：IO密集型核心线程数 = CPU核数 / （1-阻塞系数）。`

`当线程进行 I/O 操作 CPU 空闲时，启用其他线程继续使用 CPU，以提高 CPU 的使用率。例如：数据库交互，文件上传下载，网络传输等。`

### `CPU密集型与IO密集型任务的使用说明`

`当线程等待时间所占比例越高，需要越多线程，启用其他线程继续使用CPU，以此提高CPU的利用率；`
`当线程CPU时间所占比例越高，需要越少的线程，通常线程数和CPU核数一致即可，这一类型在开发中主要出现在一些计算业务频繁的逻辑中。`

### `CPU密集型任务与IO密集型任务的区别`

`计算密集型任务的特点是要进行大量的计算，消耗CPU资源，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数，避免线程或进程的切换。计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。IO密集型任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。涉及到网络、磁盘IO的任务都是IO密集型任务，`

`对于IO密集型任务，线程数越多，CPU效率越高，但也有一个限度。`




# *11 CAS是一种什么样的同步机制？*

   jdk5之前都是通过 synchronized或者lock来保证同步，从而达到线程安全的目的。但是synchronized或lock方案属于互斥锁方案，比较重量级，加锁、释放锁都会引起性能损耗的问题。

![image-20230130125256426](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230130125256426.png)





# 12.*线程加锁的方式，synchronized和lock的区别*



![image-20230215195143316](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230215195143316.png)

#### synchronized和lock的区别： synchronized编码更简单，锁机制是有jvm维护，在竞争不激烈的情况下性能更好。Lock功能更加强大灵活，竞争激烈时性能更好。

- 性能不一样：    synchronized会根据锁竞争情况 从偏向锁->轻量级锁 -> 重量级锁 升级，编程更简单

- 锁机制不一样：synchronized是在jvm层面实现的，系统会监控锁的释放与否。lock是jdk代码实现的，需要手动释放，在finall块中释放。可以采用非阻塞的方式获取锁
- synchronized可以用到代码块上，方法上。lock只能写在代码里，不能直接修改方法。

#### Lock支持的功能

- 公平锁 ：Synchronized是非公平锁，Lock支持公平锁，默认非公平锁

- 可中断锁：Reentranlock 提供了lockinterruptibly（）的功能，可中断争夺锁的操作，强锁的时候会检查是否被中断，中断直接抛出异常，退出抢锁。

- 快速反馈锁： Reentranlock 提供了trylock（）和trylock（trytimes）的功能，不等待或限定时间获取锁，更灵活。可以避免死锁的发生。

  ![image-20230215201439468](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230215201439468.png)

# *13 如何实现不可变类*

![image-20230215201602576](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230215201602576.png)

```java
public final class test {

    private final String name;

    private final Integer age;

    public test(String name, Integer age) {
        this.name = name;
        this.age = age;
    }


    public String getName() {
        return name;
    }

    public Integer getAge() {
        return age;
    }
}
```



record是jdk16新特性





# *14 抽象类和接口的区别，类可以继承多个类吗，接口可以继承多个接口吗，类可以实现多个接口吗？

![image-20230215204914013](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230215204914013.png)



# *15 描述动态代理的实现方式，分别说出相应的优缺点*

​      ![image-20230215205245384](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230215205245384.png)



# *16 现成的生命周期*

  ![image-20230216190256170](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230216190256170.png)





# 17 .*讲讲java的反射机制*

####   什么是反射：

        Reflection(反射) 是 Java 程序开发语言的特征之一，它允许运行中的 Java 程序对自身进行检查。被private封装的资源只能类内部访问，外部是不行的，但反射能直接操作类私有属性。反射可以在运行时获取一个类的所有信息，（包括成员变量，成员方法，构造器等），并且可以操纵类的字段、方法、构造器等部分。要想解剖一个类，必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法。所以先要获取到每一个字节码文件对应的Class类型的对象。
     反射就是把java类中的各种成分映射成一个个的Java对象。
         例如：一个类有：成员变量、方法、构造方法、包等等信息，利用反射技术可以对一个类进行解剖，把一个个组成部分映射成一个个对象。（其实：一个类中这些成员方法、构造方法、在加入类中都有一个类来描述）
            加载的时候：Class对象的由来是将 .class 文件读入内存，并为之创建一个Class对象。

#### 获取类

对应的字节码的对象（三种）
① 调用某个类的对象的getClass()方法，即：对象.getClass()；

```java
Person p = new Person();
Class clazz = p.getClass();
```

​        注意：此处使用的是Object类中的getClass()方法，因为所有类都继承Object类，所以调用Object类中的getClass()方法来获取。

② 调用类的class属性类获取该类对应的Class对象，即：类名.class

```java
Class clazz = Person.class;
```

③ 使用Class类中的forName()静态方法（最安全，性能最好）即：Class.forName(“类的全路径”)

```java
Class clazz = Class.forName("类的全路径");
```

​       注意：在运行期间，一个类，只有一个Class对象产生。

**![image-20230216193913411](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230216193913411.png)**



# *18 简述java内存区域*

  Java [内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)区域主要分为 Java堆，虚拟机栈，方法区，本地方法栈，程序计数器，这些都是虚拟的！不存在的，因为 Java 虚拟机本身就是虚拟的一个机器，但是真正在运行的时候虚拟机为了追求更高的速度，会把这些区域尽可能的分配在硬件的寄存器或缓存上，因为这样运行速度更快。

![image-20230219204333760](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230219204333760.png)

##### 程序计数器

程序计数器是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。

如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是 natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。

##### Java 虚拟机栈

与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是 Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。

我们常说的栈其实指的是“局部变量表”局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄）和 returnAddress 类型（指向了一条字节码指令的地址）。其中64 位长度的 long 和 double 类型的数据会占用 2 个局部变量空间（Slot），其余的数据类型只占用 1 个。

局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。

在 Java 虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常；当无法申请到足够的内存时会抛出 OutOfMemoryError 异常。

##### 本地方法栈

本地方法栈与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的 native 方法服务。与虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。

##### Java 堆

对于大多数应用来说，Java 堆是 Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都要在堆上分配内存。根据 Java 虚拟机规范的规定，Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出 OutOfMemoryError 异常。

##### 方法区

方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。根据 Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。

##### 运行时常量池

运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述等信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。既然运行时常量池是方法区的一部分，自然会受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。到这里为止，已经介绍了 Java 内存模型和 Java 内存区域并介绍了它们之间的区别。更重要的是搞清楚了在多线程情况下如何才能保证线程安全，那就是要保证 3 个特性，原子性、可见性、有序性。


# 19 *java对象创建过程*

   **java创建对象一般分为五个步骤：**

**（1）类加载检查**
**Java虚拟机（jvm）在读取一条new指令时候，首先检查能否在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否被加载、解析和初始化。如果没有，则会先执行相应的类加载过程。**

**（2）内存分配**
**在通过（1）后，则开始为新生的对象分配内存。该对象所需的内存大小在类加载完成后便可确定，因此为每个对象分配的内存大小是确定的。而分配方式主要有两种，分别为：**

**1.指针碰撞**

**应用场合：堆内存规整（通俗的说就是用过的内存被整齐充分的利用，用过的内存放在一边，没有用过的放在另外一边，而中间利用一个分界值指针对这两边的内存进行分界，从而掌握内存分配情况）。**

**即在开辟内存空间时候，将分界值指针往没用过的内存方向移动向应大小位置即可）。**

**将堆内存这样划分的代表的GC收集器算法有：Serial，ParNew**

**2.空闲列表**

**应用场合;堆内存不规整（虚拟机维护一个可以记录内存块是否可以用的列表来了解内存分配情况）**

**即在开辟内存空间时候，找到一块足够大的内存块分配给该对象即可，同时更新记录列表。**

**将堆内存这样划分的代表的GC收集器算法有：CMS**

**（3）初始化默认值**
**第（2）步完成后，紧接着，虚拟机需要将分配到的内存空间都进行初始化（即给一些默认值），这将做是为了保证对象实例的字段在Java代码中可以在不赋初值的情况下使用。程序可以访问到这些字段对用数据类型的默认值。**

**（4）设置对象头**
**初始化（3）完成后，虚拟机对对象进行一些简单设置，如标记该对象是哪个类的实例，这个对象的hash码，该对象所处的年龄段等等（这些可以理解为对象实例的基本信息）。这些信息被写在对象头中。jvm根据当前的运行状态，会给出不同的设置方式。**

**（5）执行初始化方法**
**在（4）完成后，最后执行由开发人员编写的对象的初始化方法，把对象按照开发人员的设计进行初始化，一个对象便创建出来了。**







# *20 对象的访问定位有哪两种方式？*

   建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位访问堆中的对象的具体位置，所以对象的访问方式取决于具体的虚拟机实现而定。目前主流的访问方式有使用句柄和直接指针两种。
**1、先讲一下使用句柄的访问方式**

![img](https://gitee.com/dwc12/image/raw/master/typoraImage/20190808223344970.png)

如图所示，如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，句柄池中放的是一个一个的句柄，句柄中存的是对象实例数据与对象类型数据的指针引用。栈中局部变量里reference中存储的是对象句柄的地址，而句柄中包含了对象实例数据与类型数据的具体地址信息，相当于二级指针。

**2、第二种访问方式是直接指针**

![img](https://gitee.com/dwc12/image/raw/master/typoraImage/20190808224021468.png)

如图所示，直接指针访问对象，栈中局部变量里reference中存储的就是对象地址，相当于一级指针**。**

**3、对比**

这两种对象访问方式各有利弊，使用句柄访问的最大好处就是在移动对象时（如垃圾回收的标记整理算法在回收完垃圾对象后需要把剩下存活的对象进行整理移动，以减少内存碎片），reference中存储的地址是稳定的地址，不需要修改，仅需要修改对象句柄的地址；但是如果使用直接指针方式的话，在对象被移动的时候需要修改reference中存储的地址。从效率方面比较的话，直接指针的效率要高于句柄，因为直接指针的方式只进行了一次指针定位，节省了时间开销，HotSpot采用的直接指针的实现方式。



# *21 java池化思想？*

在我们平常的编码中，通常会将一些对象保存起来，这主要考虑的是对象的创建成本。比如像线程资源、数据库连接资源或者 TCP 连接等，这类对象的初始化通常要花费比较长的时间，如果频繁地申请和销毁，就会耗费大量的系统资源，造成不必要的性能损失。并且这些对象都有一个显著的特征，就是通过轻量级的重置工作，可以循环、重复地使用。这个时候，我们就可以使用一个虚拟的池子，将这些资源保存起来，当使用的时候，我们就从池子里快速获取一个即可。在 Java 中，池化技术应用非常广泛，常见的就有[数据库连接池](https://so.csdn.net/so/search?q=数据库连接池&spm=1001.2101.3001.7020)、线程池等，



# ***22 spring中bean的生命周期***

![流程](https://gitee.com/dwc12/image/raw/master/typoraImage/cfbab93142834a37803ba692fcd8f0fa.png)

##  生命周期的概要流程

Bean 的生命周期概括起来就是 **4 个阶段**：

1. 实例化（Instantiation）
2. 属性赋值（Populate）
3. 初始化（Initialization）
4. 销毁（Destruction）

![img](https://gitee.com/dwc12/image/raw/master/typoraImage/7701eb466f94401b9f08e2c9735d7461.png)

实例化：第 1 步，实例化一个 bean 对象；

属性赋值：第 2 步，为 bean 设置相关属性和依赖；

初始化：第 3~7 步，步骤较多，其中第 5、6 步为初始化操作，第 3、4 步为在初始化前执行，第 7 步在初始化后执行，该阶段结束，才能被用户使用；

销毁：第 8~10步，第8步不是真正意义上的销毁（还没使用呢），而是先在使用前注册了销毁的相关调用接口，为了后面第9、10步真正销毁 bean 时再执行相应的方法。


# *23 说说sleep方法和wait方法的区别*

**线程sleep 和wait 的区别：**

1、这两个方法来自不同的类分别是Thread和Object

2、最主要是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。

3、wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用（使用范围）

4、sleep必须捕获异常，wait，notify和notifyAll同样需要捕获异常





# *24 java对象在内存中的分布*

![img](https://gitee.com/dwc12/image/raw/master/typoraImage/20190808003228577.png)

##### 1、对象头

对象头用于存储对象的元数据信息

对象头又可以分为两块内容：

第一部分用于存储对象自身的运行时数据，如0偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机中分别位32bit和64bit，官方称它为 Mark Word，这部分在32位虚拟机占用4个字节，在64位虚拟机占用**8个字节** 因为对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。也就是说，Mark Word会随着程序的运行发生变化，变化状态如下

32位虚拟机：

![img](https://gitee.com/dwc12/image/raw/master/typoraImage/20200228170830806.png)

64位虚拟机：

![](https://gitee.com/dwc12/image/raw/master/typoraImage/20200228170830806.png)

对象头的另一部分是类型指针，指向它的类元数据的指针 Klass Pointer，用于判断对象属于哪个类的实例，默认开启压缩Klass Pointer占4个字节，不开启压缩的话占8个字节。另外，如果对像是一个**数组**，那在对象头中还必须有一块用于记录数组长度的数据，4个字节来记录数组的长度。因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组的大小。所以默认情况下，**正常对象头的大小是12字节，数组情况下对象头的大小是16字节**


##### 2、实例数据

实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录下来。父类定义的变量会出现在子类定义的变量的前面。各字段的分配策略为longs/doubles、ints、shorts/chars、bytes/boolean、oops(ordinary object pointers)，相同宽度的字段总是被分配到一起，便于之后取数据。

##### 3、对齐填充

对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。为什么需要有对齐填充呢？由于hotspot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话，就是对象的大小必须是8字节的整数倍。因此，当对象头和对象实例数据部分不是8个字节的整数倍时，就需要通过对齐填充来补全。
![image-20230222213402402](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230222213402402.png)





# 25 mysql大表优化

当mysql单表记录过多时，增删改查性能会急速下降，这时候就需要我们对大表进行优化。

### 单表优化

除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以[整型](https://so.csdn.net/so/search?q=整型&spm=1001.2101.3001.7020)值为主的表在`千万级`以下，[字符串](https://so.csdn.net/so/search?q=字符串&spm=1001.2101.3001.7020)为主的表在`五百万`以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量：

#### 字段

- 尽量使用`TINYINT`、`SMALLINT`、`MEDIUM_INT`作为整数类型而非`INT`，如果非负则加上`UNSIGNED`
- `VARCHAR`的长度只分配真正需要的空间
- 使用枚举或整数代替字符串类型
- 尽量使用`TIMESTAMP`而非`DATETIME`，
- 单表不要有太多字段，建议在20以内
- 避免使用NULL字段，很难查询优化且占用额外索引空间
- 用整型来存IP

#### 索引

- 索引并不是越多越好，要根据查询有针对性的创建，考虑在`WHERE`和`ORDER BY`命令上涉及的列建立索引，可根据`EXPLAIN`来查看是否用了索引还是全表扫描
- 应尽量避免在`WHERE`子句中对字段进行`NULL`值判断，否则将导致引擎放弃使用索引而进行全表扫描
- 值分布很稀少的字段不适合建索引，例如"性别"这种只有两三个值的字段
- 字符字段只建前缀索引
- 字符字段最好不要做主键
- 不用外键，由程序保证约束
- 尽量不用`UNIQUE`，由程序保证约束
- 使用多列索引时注意顺序和查询条件保持一致，同时删除不必要的单列索引

#### 查询SQL

- 可通过开启慢查询日志来找出较慢的SQL
- 不做列运算：`SELECT id WHERE age + 1 = 10`，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边
- sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库
- 不用`SELECT *`
- `OR`改写成`IN`：`OR`的效率是n级别，`IN`的效率是log(n)级别，in的个数建议控制在200以内
- 不用函数和触发器，在应用程序实现
- 避免`%xxx`式查询
- 少用`JOIN`
- 使用同类型进行比较，比如用`'123'`和`'123'`比，`123`和`123`比
- 尽量避免在`WHERE`子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
- 对于连续数值，使用`BETWEEN`不用`IN`：`SELECT id FROM t WHERE num BETWEEN 1 AND 5`
- 列表数据不要拿全表，要使用`LIMIT`来分页，每页数量也不要太大

#### 系统调优参数

可以使用下面几个工具来做基准测试：

- [sysbench](https://github.com/akopytov/sysbench)：一个模块化，跨平台以及多线程的性能测试工具
- [iibench-mysql](https://github.com/tmcallaghan/iibench-mysql)：基于 Java 的 MySQL/Percona/MariaDB 索引进行插入性能测试工具
- [tpcc-mysql](https://github.com/Percona-Lab/tpcc-mysql)：Percona开发的TPC-C测试工具

具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数：

- back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500
- wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时
- max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限
- thread_concurrency：并发线程数，设为CPU核数的两倍
- skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问
- key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询`show status like 'key_read%'`，保证`key_reads / key_read_requests`在0.1%以下最好
- innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询`show status like 'Innodb_buffer_pool_read%'`，保证` (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests`越高越好
- innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小
- innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB
- query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率`(Qcache_hits/(Qcache_hits+Qcache_inserts)*100))`进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.
  可以通过命令`show status like 'Qcache_%'`查看目前系统Query catch使用大小
- read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能
- sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加`ORDER BY`的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小
- read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。
- record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值
- thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的
- table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM

### 读写分离

也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离

### 表分区

MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码

对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引

​           ![img](https://gitee.com/dwc12/image/raw/master/typoraImage/163758-20181116175833498-559330629.png)

用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过`EXPLAIN PARTITIONS`来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下图5条记录落在两个分区上：

```
mysql> explain partitions select count(1) from user_partition where id in (1,2,3,4,5);
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
| id | select_type | table          | partitions | type  | possible_keys | key     | key_len | ref  | rows | Extra                    |
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
|  1 | SIMPLE      | user_partition | p1,p4      | range | PRIMARY       | PRIMARY | 8       | NULL |    5 | Using where; Using index |
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
1 row in set (0.00 sec)
```

分区的好处是：

- 可以让单表存储更多的数据
- 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作
- 部分查询能够从查询条件确定只落在少数分区上，速度会很快
- 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备
- 可以使用分区表来避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争
- 可以备份和恢复单个分区

分区的限制和缺点：

- 一个表最多只能有1024个分区
- 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来
- 分区表无法使用外键约束
- NULL值会使分区过滤无效
- 所有分区必须使用相同的存储引擎

分区适合的场景有：

- 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示：

  ```mysql
  CREATE TABLE members (
      firstname VARCHAR(25) NOT NULL,
      lastname VARCHAR(25) NOT NULL,
      username VARCHAR(16) NOT NULL,
      email VARCHAR(35),
      joined DATE NOT NULL
  )
  PARTITION BY RANGE( YEAR(joined) ) (
      PARTITION p0 VALUES LESS THAN (1960),
      PARTITION p1 VALUES LESS THAN (1970),
      PARTITION p2 VALUES LESS THAN (1980),
      PARTITION p3 VALUES LESS THAN (1990),
      PARTITION p4 VALUES LESS THAN MAXVALUE
  );
  ```

查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。

- 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存

### 垂直拆分

垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联

比如原始的用户表是：

​             ![img](https://gitee.com/dwc12/image/raw/master/typoraImage/163758-20181116180019100-1010499888.png)

垂直拆分后是：

​             ![img](https://gitee.com/dwc12/image/raw/master/typoraImage/163758-20181116180104899-2022030573.png)

垂直拆分的优点是：

- 可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I/O次数(每次查询时读取的Block 就少)
- 可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起
- 数据维护简单

缺点是：

- 主键出现冗余，需要管理冗余列
- 会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力
- 依然存在单表数据量过大的问题（需要水平拆分）
- 事务处理复杂

### 水平拆分

#### 概述

水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。前面的表分区本质上也是一种特殊的库内分表

库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决

前面垂直拆分的用户表如果进行水平拆分，结果是：

​              ![img](https://gitee.com/dwc12/image/raw/master/typoraImage/163758-20181116180134132-1914343381.png)

实际情况中往往会是垂直拆分和水平拆分的结合，即将`Users_A_M`和`Users_N_Z`再拆成`Users`和`UserExtras`，这样一共四张表

水平拆分的优点是:

- 不存在单库大数据和高并发的性能瓶颈
- 应用端改造较少
- 提高了系统的稳定性和负载能力

缺点是：

- 分片事务一致性难以解决
- 跨节点Join性能差，逻辑复杂
- 数据多次扩展难度跟维护量极大



# *26 mysql的事务隔离级别*

 **一、什么是事务？**
事务是逻辑上的一组操作，要么全执行，要么全不执行。

事务最经典栗子也经常被拿出来的栗子就是银行转账了。比如小明要给小红转账1000元，这个转账会涉及到两个关键操作：将小明的余额减1000元，将小红的余额减1000元。万一这两个操作之间突然出现错误，导致小明余额减少但是小红余额没有增加，这种情况是肯定不允许的。事务就是保证这两个关键操作要么都成功，要么都不成功。

**二、事务的特性（ACID）**

**原子性：**事务最小的执行单位，不允许分割。事务的原子性确保动作要么全部执行，要么全部不执行。
**一致性：**执行事务的前后，数据保持一致。例如转账的业务中，无论事务是否成功，转账者和收款人的总额应该是不变的。
**隔离性：**并发访问数据库时，一个用户的事务不应该被其他事务所影响，各并发事务之间数据库是独立的。
**持久性：**一个事务被提交后，它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有影响。

** **
在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但是可能会带来以下的问题：

**脏读（Dirty read）：**当一个事务正在访问数据并且对其进行了修改，但是还没提交事务，这时另外一个事务也访问了这个数据，然后使用了这个数据，因为这个数据的修改还没提交到数据库，所以另外一个事务读取的数据就是“脏数据”，这种行为就是“脏读”，依据“脏数据”所做的操作可能是会出现问题的。
**修改丢失（Lost of modify）**：是指一个事务读取一个数据时，另外一个数据也访问了该数据，那么在第一个事务修改了这个数据之后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，这种情况就被称为修改丢失。例如：事务1读取表中数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果都是19，但是事务1的修改记录丢失了。
**不可重复读（Unrepeatableread）**：指在一个事务内多次读取同一数据，在这个事务还没结束时，另外一个事务也访问了这个数据并对这个数据进行了修改，那么就可能造成第一个事务两次读取的数据不一致，这种情况就被称为不可重复读。
**幻读（Phantom read）**：幻读与不可重复读类似，幻读是指一个事务读取了几行数据，这个事务还没结束，接着另外一个事务插入了一些数据，在随后的查询中，第一个事务读取到的数据就会比原本读取到的多，就好像发生了幻觉一样，所以称为幻读。
**不可重复读和幻读区别：**
不可重复读的重点是修改，幻读的重点是新增或者删除。

**四、事务隔离级别**
SQL标准定义了四个隔离级别：

**读取未提交（READ-UNCOMMITTED）：**最低的隔离级别，允许读取尚未提交的数据变更，可能造成脏读、不可重复读、幻读。
**读取已提交（READ-COMMITTED）：**允许读取并发事务已经提交的数据，可以避免脏读，但是可能造成不可重复、幻读。
**可重复读（REPEATABLE-READ）：**对同一字段多次读取的结果都是一致的，除非本身事务修改，可以避免脏读和不可重复读，但是可能造成幻读。
**可串行化（SERIALIZABLE）：**最高的隔离级别，完全服从ACID的隔离级别，所以的事务依次执行，可以避免脏读、不可重复读、幻读。

| 隔离级别   | 脏读 | 不可重复读 | 幻读 |
| ---------- | ---- | ---------- | ---- |
| 读取未提交 | √    | √          | √    |
| 读取已提交 | ×    | √          | √    |
| 可重复读   | ×    | ×          | √    |
| 可串行化   | ×    | ×          | ×    |





# *27 JDK 和jre jvm的关系*

![image-20230224094121558](https://gitee.com/dwc12/image/raw/master/typoraImage/image-20230224094121558.png)

jdk包含了jre 和一些编译工具，检测工具

jre 包含了jvm 和java基础类库

jvm java虚拟机





# 28  cap定理和base理论 

**一.CAP定理**
CAP原则又称作CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance），这三个要素最多只能同时实现两点，不可能三者兼顾。

一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否有同样的值（等同于所有节点访问同一份最新的数据副本）。

通过某个节点的写操作结果对后面其他节点的读操作可见；

如果更新数据后，并发访问情况下可立即感知该更新，被称作强一致性；

如果允许之后的部分或者全部感知不到该更新，被称作弱一致性；

若在之后的一段时间（通常该时间不固定）后，一定可以感知该更新，称为最终一致性。

可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求（对数据更新具备高可用性）。

任何一个没有发生故障的节点必须在有限的时间内返回合理的结果。

分区容忍性（P）：以实际效果而言，分区当当与对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。

部分节点宕机或者无法与其他节点通信时，各分区还可以保持分布式系统的功能。

一般分区容忍性都要求有保障，因此很多时候是在可用性与一致性之间做权衡。

CAP原则的精髓就是要么AP，要么CP，要么AC，但是不存在CAP。如果在某个分布式系统中数据无副本，那么系统必然满足强一致性条件，因为只有独一数据，不会出现数据不一致的情况，此时C和P两要素具备，但是如果系统发生了网络分区状况或宕机，必然导致某些数据不可以访问，此时可用性条件就不能被满足，即在此情况下获得了CP系统，但是CAP不可同时满足。

因此，在进行分布式架构设计时，必须做出取舍。当前一般是通过分布式缓存中各节点的最终一致性来提高系统的性能，通过使用多节点之间的数据异步复制技术来实现集群化的数据一致性。通常使用memcached之类的NOSQL作为实现手段。虽然memcached也可以是分布式集群环境的，但是对于一份数据来说，它总是存储在某一台memcached服务器上。如果发生网络故障或是服务器死机，则存储在这台服务器上的所有数据都将不可访问。由于数据是存储在内从中的，重启服务器，将导致数据全部丢失。当然也可以自己实现一套机制，用来在分布式memcached之间进行数据的同步和持久化，但是实现难度非常大。

 

1.1.可用的抉择
由于CAP理论的特点，而由于网络硬件肯定会出现延迟丢包等问题，所以分区容错性是我们必须要实现的。所以我们只能在一致性和可用性之间作出权衡，没有NOSQL系统能同时保证这三点。而对于web2.0网站来说，关系数据库的很多主要特性往往无用武之地。

1.1.1.数据库事务一致性要求

很多web实时系统并不要求严格的数据库事务，对读一致性的要求很低，有些场合对写一致性要求并不高，允许实现最终一致性。

1.1.2.数据库的写实时性和读实时性要求

对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出来这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比方说发一条消息之 后，过几秒乃至十几秒之后，我的订阅者才看到这条动态是完全可以接受的。

1.1.3.对复杂的SQL查询，特别是多表关联查询的需求

任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的报表查询，特别是性能要求很高的网站，从需求以及产品设计角 度，就避免了这种情况的产生，往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能被极大的弱化了。

1.2.与NoSQL的关系
传统的关系型数据库在功能支持上通常很宽泛，从简单的键值查询，到复杂的多表联合查询再到事务机制的支持。而与之不同的是，NoSQL系统通常注重性能和扩展性，而非事务机制（事务就是强一致性的体现）。

传统的SQL数据库的事务通常都是支持ACID的强事务机制。A代表原子性，即在事务中执行多个操作是原子性的，要么事务中的操作全部执行，要么一个都不执行；C代表一致性，即保证进行事务的过程中整个数据库的状态是一致的，不会出现数据花掉的情况；I代表隔离性，即两个事务不会相互影响，覆盖彼此数据等；D表示持久化，即事务一旦完成，那么数据应该是被写到安全的，持久化存储的设备上（比如磁盘）。

NoSQL系统仅提供对行级别的原子性保证，也就是说同时对同一个Key下的数据进行的两个操作，在实际执行的时候是会串行的执行，保证了每一个Key-Value对不会被破坏。

1.3.与BASE的关系
BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写。

BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。接下来我们着重对BASE中的三要素进行详细讲解。

（1）基本可用：指分布式系统在出现不可预知故障的时候，允许损失部分可用性。

注意，这绝不等价于系统不可用，以下两个就是“基本可用”的典型例子：

响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。

功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

（2）弱状态：也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

（3）最终一致性：强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

1.4.一致性方案
1.4.1.Master-slave

RDBMS的读写分离即为典型的Master-slave方案；

同步复制可保证强一致性，但会影响可用性；

异步复制可提供高可用性，但会降低一致性。

1.4.2.WNR

主要是去中心化（P2P）的分布式系统中。DynamoDB与Cassandra即采用此方案；

N代表副本数，W代表每次写操作要保证的最少写成功的副本数，R代表每次读至少读取的副本数；

当W+R>N时，可保证每次读取的数据至少有一个副本具有最新的更新；

多个写操作的顺序难以保证，可能导致多副本间的写操作顺序不一致，Dynamo通过向量时钟保证最终一致性。

1.4.3.Paxos及其变种

Google的Chubby、Zookpeer的Zab、RAFT等。

1.5.取舍策略
CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。传统的关系型数据库RDBMS：Oracle、MySQL就是CA。

CP without A：如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。

AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。

1.6.选择权衡
选择的关键点取决于业务场景。

对于大多数互联网应用来说（如网易门户），因为机器数量庞大，部署节点分散，网络故障是常态，可用性是必须需要保证的，所以只有设置一致性来保证服务的AP，通常常见的高可用服务吹嘘5个9 6个9服务SLA稳定性就本都是放弃C选择AP

对于需要确保强一致性的场景，如银行，通常会权衡CA和CP模型，CA模型网络故障时完全不可用，CP模型具备部分可用性，实际的选择需要通过业务场景来权衡（并不是所有情况CP都好于CA，只能查看信息不能更新信息有时候从产品层面还不如直接拒绝服务）


**二.BASE理论**
BASE理论是由eBay架构师提出的。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。其核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，才用适当的方式来使系统打到最终一致性。

2.1.CAP的3选2伪命题
实际上，不是为了P（分区容错性），必须在C（一致性）和A（可用性）之间任选其一。分区的情况很少出现，CAP在大多时间能够同时满足C和A。

对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理：

探知分区的发生；

进入显示的分区模式，限制某些操作；

启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。

2.2.BASE理论简介
BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。

其核心思想是：

“既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。”

2.3.BASE理论的内容
基本可用（Basically Available）

软状态（Soft State）

最终一致性（Eventually Consistent）

2.3.1.基本可用

什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：

响应时间上的损失：正常情况下，一个在线搜索引擎需要0.5秒内返回给用户相应的查询结果，但由于出现异常（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。

功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

2.3.2.软状态

什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。

软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。

2.3.3.最终一致性

上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。

而在实际工程实践中，最终一致性分为5种：

2.3.3.1.因果一致性（Causal consistency）

因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。

2.3.3.2.读己之所写（Read your writes）

读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。

2.3.3.3.会话一致性（Session consistency）

会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。

2.3.3.4.单调读一致性（Monotonic read consistency）

单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。

2.3.3.5.单调写一致性（Monotonic write consistency）

单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。

在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。

实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。

小结

总体来说BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不同于ACID的强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID和BASE理论往往又会结合使用。

三.分布式系统的典型应用
分布式系统是一个非常广泛的概念，它最终要落实到解决实际问题上，不同的问题有不同的方法和架构。所有的开源软件都是以某个应用场景出现，而纯粹以“分布式”概念进行划分的比较少见。

但如果以算法划分，到能分出几类：

1.以Leader选举为主的一类算法，比如paxos、viewstamp，就是现在zookeeper、Chuby等工具的主体

2.以分布式事务为主的一类主要是二段提交，这些分布式数据库管理器及数据库都支持

3.以若一致性为主的，主要代表是Cassandra的W、R、N可调节的一致性

4.以租赁机制为主的，主要是一些分布式锁的概念，目前还没有看到纯粹“分布式”锁的实现

5.以失败探测为主的，主要是Gossip和phi失败探测算法，当然也包括简单的心跳

6.以弱一致性、因果一致性、顺序一致性为主的，开源尚不多，但大都应用在Linkedin、Twitter、Facebook等公司内部 7当然以异步解耦为主的，还有各类Queue







# 29  自动装箱和拆箱

Java自动装箱和拆箱定义
       Java 1.5中引入了自动装箱和拆箱机制：

```java
   (1)自动装箱：把基本类型用它们对应的引用类型包装起来，使它们具有对象的特质，可以调用toString()、hashCode()、getClass()、equals()等方法。

    如下：

    Integer a=3;//这是自动装箱

    其实编译器调用的是static Integer valueOf(int i)这个方法,valueOf(int i)返回一个表示指定int值的Integer对象,那么就变成这样: 

    Integer a=3;   =>    Integer a=Integer.valueOf(3);

    (2)拆箱：跟自动装箱的方向相反，将Integer及Double这样的引用类型的对象重新简化为基本类型的数据。

     如下：

     int i = new Integer(2);//这是拆箱

     编译器内部会调用int intValue()返回该Integer对象的int值

     注意：自动装箱和拆箱是由编译器来完成的，编译器会在编译期根据语法决定是否进行装箱和拆箱动作。
```
